{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4022bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "import pytz\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e23ff",
   "metadata": {},
   "source": [
    "# Batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b12d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "# batch\n",
    "\n",
    "def convert_date_to_recent_data(df:pd.DataFrame, date_column:str='lpep_pickup_datetime') -> pd.Series:\n",
    "    \"\"\" This function simulates a real-world scenario where the date column is always represented as recent data.\n",
    "    \"\"\"\n",
    "    lpep_pickup_datetime_f = pd.to_datetime(df[date_column].dt.strftime('%Y-%m-%d'))\n",
    "    today = pd.to_datetime(datetime.now().strftime('%Y-%m-%d'))\n",
    "    time_diff = today - lpep_pickup_datetime_f\n",
    "    return lpep_pickup_datetime_f + np.min(time_diff)\n",
    "\n",
    "def recreate_empty_table(conn, table_name:str='trips') -> None:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create a table with the desired columns\n",
    "    create_table_query = f\"\"\"\n",
    "\n",
    "        DROP TABLE IF EXISTS {table_name};\n",
    "\n",
    "        CREATE TABLE {table_name} (\n",
    "            time TIMESTAMPTZ,\n",
    "            trip_distance FLOAT,\n",
    "            payment_type VARCHAR(10)\n",
    "        )\n",
    "        \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "\n",
    "def insert_sample_data(df:pd.DataFrame, engine, table_name:str='trips') -> None:\n",
    "    # Insert data from the DataFrame into the table\n",
    "    engine = create_engine(f'postgresql://postgres:example@localhost:5432/postgres')\n",
    "    df.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "    print(f'FINISHED')\n",
    "\n",
    "\n",
    "####################################\n",
    "####################################\n",
    "####################################\n",
    "\n",
    "df = pd.read_parquet(\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2024-01.parquet\")\n",
    "\n",
    "time = convert_date_to_recent_data(df)\n",
    "cols = ['trip_distance', 'payment_type']\n",
    "df2 = df[cols].copy() # do a smaller copy of the dataframe\n",
    "df2['time'] = time\n",
    "\n",
    "# Create a PostgreSQL engine\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"example\"\n",
    ")\n",
    "    \n",
    "recreate_empty_table(conn)\n",
    "engine = create_engine(f'postgresql://postgres:example@localhost:5432/postgres')\n",
    "insert_sample_data(df2, engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b960cd6",
   "metadata": {},
   "source": [
    "# Simulate realtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4cbd7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 inserted into the database\n",
      "119 inserted into the database\n",
      "0 inserted into the database\n",
      "272 inserted into the database\n",
      "35 inserted into the database\n",
      "85 inserted into the database\n",
      "25 inserted into the database\n",
      "349 inserted into the database\n",
      "48 inserted into the database\n",
      "172 inserted into the database\n",
      "336 inserted into the database\n",
      "80 inserted into the database\n",
      "188 inserted into the database\n",
      "18 inserted into the database\n",
      "106 inserted into the database\n",
      "5 inserted into the database\n",
      "0 inserted into the database\n",
      "126 inserted into the database\n",
      "319 inserted into the database\n",
      "175 inserted into the database\n",
      "0 inserted into the database\n",
      "0 inserted into the database\n",
      "142 inserted into the database\n",
      "118 inserted into the database\n",
      "0 inserted into the database\n",
      "251 inserted into the database\n",
      "88 inserted into the database\n",
      "18 inserted into the database\n",
      "0 inserted into the database\n",
      "0 inserted into the database\n",
      "0 inserted into the database\n",
      "251 inserted into the database\n",
      "144 inserted into the database\n",
      "221 inserted into the database\n",
      "0 inserted into the database\n",
      "577 inserted into the database\n",
      "198 inserted into the database\n",
      "273 inserted into the database\n",
      "40 inserted into the database\n",
      "158 inserted into the database\n",
      "390 inserted into the database\n",
      "93 inserted into the database\n",
      "99 inserted into the database\n",
      "329 inserted into the database\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# sort a integer between 1 and 5 with uniform distribution\u001b[39;00m\n\u001b[1;32m     14\u001b[0m wait_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2024-01.parquet\")\n",
    "\n",
    "time = convert_date_to_recent_data(df)\n",
    "cols = ['trip_distance', 'payment_type']\n",
    "df2 = df[cols].copy() # do a smaller copy of the dataframe\n",
    "df2['time'] = time\n",
    "\n",
    "# Create a PostgreSQL engine\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"example\"\n",
    ")\n",
    "\n",
    "recreate_empty_table(conn)\n",
    "df2_ix = 0\n",
    "while df2_ix < df2.shape[0]:                            # while all rows haven't been processed\n",
    "    # \n",
    "    data_amount = int(np.random.normal(100, 200))       # sort a specific number of rows\n",
    "    sub_df = df2.iloc[df2_ix:df2_ix+data_amount].copy() # get the subset of the data\n",
    "    tz = pytz.timezone('Japan')\n",
    "    sub_df['time'] = tz.localize(datetime.now())        # simulate that data came from specific day\n",
    "    df2_ix = df2_ix + data_amount                       # update the index\n",
    "    sub_df.to_sql('trips', engine, if_exists='append', index=False)\n",
    "    print(f'{sub_df.shape[0]} inserted into the database')\n",
    "    # sort a integer between 1 and 5 with uniform distribution\n",
    "    wait_time = np.random.randint(1, 5)\n",
    "    time.sleep(wait_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2024-01.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a045702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "df = pd.read_parquet(\"data/green_tripdata_2022-01.parquet\")\n",
    "df = df.sample(frac=0.05)\n",
    "\n",
    "tz = pytz.timezone('Japan')\n",
    "time_ = pd.to_datetime('2022-01-01').tz_localize(tz)\n",
    "cols = ['trip_distance', 'payment_type']\n",
    "df2 = df[cols].copy() # do a smaller copy of the dataframe\n",
    "df2['time'] = time_\n",
    "df2.to_csv('data/ride_sharing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f91763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile                           \u001b[1m\u001b[36mprometheus\u001b[m\u001b[m\n",
      "baseline_model_nyc_taxi_data.ipynb   \u001b[1m\u001b[36mprometheus_data\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mconfig\u001b[m\u001b[m                               requirements.txt\n",
      "\u001b[1m\u001b[36mdashboards\u001b[m\u001b[m                           simple_batch_insert_postgres.py\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m                                 simple_real_time_insert_postgres.py\n",
      "docker-compose.yml                   test.ipynb\n",
      "\u001b[1m\u001b[36mevidently_grafana_monitoring_service\u001b[m\u001b[m \u001b[1m\u001b[36mutils\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mhomework-05\u001b[m\u001b[m                          \u001b[1m\u001b[36mworkspace\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mmodels\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45cad019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbf078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
